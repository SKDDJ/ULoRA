trainer:
  accelerator: gpu
  devices: [0,]
  # precision: 16
  num_nodes: 1
  # max_epochs: 10
  # val_check_interval: 500
  check_val_every_n_epoch: 1
  # val_check_interval: 0.5
  val_check_interval: 0.25
  log_every_n_steps: 1
  # sync_batchnorm: True
  # gradient_clip_val: 0.5
  deterministic: False

  precision: 16-mixed
  logger:
    class_path: pytorch_lightning.loggers.CSVLogger
    init_args:
      save_dir: output
      name: cifar10-sara
model:
  model_name: vit-b16-224-in21k
  training_mode: sara
  optimizer: adamw
  lr: 3e-2
  weight_decay: 8e-4
  scheduler: cosine
  warmup_steps: 500
  lora_r: 8
  lora_alpha: 8

data:
  dataset: cifar10
  root: data/
  size: 224
  batch_size: 128
  workers: 8
model_checkpoint:
  filename: best-step-{step}-{val_acc:.4f}
  monitor: val_acc
  save_last: true
  mode: max

