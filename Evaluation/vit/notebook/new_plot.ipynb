{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/sara/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Flowers102 doesn't have 'classes' attribute, using class indices instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2140236/1497124067.py:216: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to publication_quality_dataset_samples.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import ssl\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import (\n",
    "    CIFAR10,\n",
    "    CIFAR100,\n",
    "    DTD,\n",
    "    EuroSAT,\n",
    "    FGVCAircraft,\n",
    "    Flowers102,\n",
    "    OxfordIIITPet,\n",
    "    StanfordCars,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Disable SSL certificate verification (use with caution)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Define datasets and their configurations\n",
    "DATASET_CONFIG = {\n",
    "    \"CIFAR-10\": {\n",
    "        \"class_names\": None,  # Will be extracted from the dataset later\n",
    "        \"train\": partial(CIFAR10, train=True, download=True),\n",
    "        \"test\": partial(CIFAR10, train=False, download=True),\n",
    "        \"num_classes\": 10,\n",
    "    },\n",
    "    \"CIFAR-100\": {\n",
    "        \"class_names\": None,\n",
    "        \"train\": partial(CIFAR100, train=True, download=True),\n",
    "        \"test\": partial(CIFAR100, train=False, download=True),\n",
    "        \"num_classes\": 100,\n",
    "    },\n",
    "    \"EuroSAT\": {\n",
    "        \"class_names\": None,\n",
    "        \"train\": partial(EuroSAT, download=True),\n",
    "        \"test\": partial(EuroSAT, download=True),\n",
    "        \"num_classes\": 10,  # EuroSAT has 10 classes\n",
    "    },\n",
    "    \"Flowers102\": {\n",
    "        \"class_names\": None,\n",
    "        \"train\": partial(Flowers102, split=\"train\", download=True),\n",
    "        \"test\": partial(Flowers102, split=\"val\", download=True),\n",
    "        \"num_classes\": 102,\n",
    "    },\n",
    "    # \"Oxford-IIIT-Pets\": {\n",
    "    #     \"class_names\": None,\n",
    "    #     \"train\": partial(OxfordIIITPet, split=\"trainval\", download=True),\n",
    "    #     \"test\": partial(OxfordIIITPet, split=\"test\", download=True),\n",
    "    #     \"num_classes\": 37,\n",
    "    # },\n",
    "    # \"DTD\": {\n",
    "    #     \"class_names\": None,\n",
    "    #     \"train\": partial(DTD, split=\"train\", download=True),\n",
    "    #     \"test\": partial(DTD, split=\"val\", download=True),\n",
    "    #     \"num_classes\": 47,\n",
    "    # },\n",
    "    \"FGVC-Aircraft\": {\n",
    "        \"class_names\": None,\n",
    "        \"train\": partial(FGVCAircraft, split=\"train\", download=True),\n",
    "        \"test\": partial(FGVCAircraft, split=\"val\", download=True),\n",
    "        \"num_classes\": 100,\n",
    "    },\n",
    "    \"Stanford Cars\": {\n",
    "        \"class_names\": None,\n",
    "        \"train\": partial(StanfordCars, split=\"train\", download=True),\n",
    "        \"test\": partial(StanfordCars, split=\"test\", download=True),\n",
    "        \"num_classes\": 196,\n",
    "    },\n",
    "}\n",
    "\n",
    "def im_convert(tensor):\n",
    "    \"\"\"\n",
    "    Denormalize the tensor and convert it to a NumPy array for visualization.\n",
    "    \"\"\"\n",
    "    image = tensor.clone().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    image = image * 0.5 + 0.5  # Denormalize\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image\n",
    "\n",
    "def get_subset(dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Get a subset of the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (torch.utils.data.Dataset): The dataset.\n",
    "        num_samples (int): Number of samples to get.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.Subset: A subset of the dataset.\n",
    "    \"\"\"\n",
    "    indices = list(range(min(num_samples, len(dataset))))\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "def get_class_names(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Get class names for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (torch.utils.data.Dataset): Dataset instance.\n",
    "        dataset_name (str): Name of the dataset.\n",
    "\n",
    "    Returns:\n",
    "        list or None: List of class names, or None if not available.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, 'classes'):\n",
    "        return dataset.classes\n",
    "    else:\n",
    "        # For datasets without 'classes' attribute, return None\n",
    "        print(f\"{dataset_name} doesn't have 'classes' attribute, using class indices instead.\")\n",
    "        return None\n",
    "\n",
    "def load_datasets(root, transform, num_samples=5):\n",
    "    \"\"\"\n",
    "    Load and prepare datasets for visualization.\n",
    "\n",
    "    Parameters:\n",
    "        root (str): Root directory where datasets are stored.\n",
    "        transform (torchvision.transforms.Compose): Transforms to apply.\n",
    "        num_samples (int): Number of samples per dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dictionary mapping dataset names to subsets, dictionary mapping dataset names to class names.\n",
    "    \"\"\"\n",
    "    datasets_to_show = {}\n",
    "    class_names_dict = {}\n",
    "    for name, config in DATASET_CONFIG.items():\n",
    "        try:\n",
    "            dataset = config[\"train\"](root=root, transform=transform)\n",
    "            datasets_to_show[name] = get_subset(dataset, num_samples)\n",
    "            class_names = get_class_names(dataset, name)\n",
    "            class_names_dict[name] = class_names\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset {name}: {e}\")\n",
    "    return datasets_to_show, class_names_dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_datasets(datasets_to_show, class_names_dict, num_samples=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Create a publication-quality visualization of samples from multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "        datasets_to_show (dict): Dictionary mapping dataset names to dataset subsets.\n",
    "        class_names_dict (dict): Dictionary mapping dataset names to lists of class names.\n",
    "        num_samples (int): Number of samples per dataset.\n",
    "        save_path (str or None): Path to save the image. If None, display the image.\n",
    "    \"\"\"\n",
    "    num_datasets = len(datasets_to_show)\n",
    "    \n",
    "    # # Set up the plot style using a valid style\n",
    "    plt.style.use('seaborn-v0_8-paper')  # Use a valid matplotlib style\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "    \n",
    "    \n",
    "    # Create figure and gridspec\n",
    "    fig = plt.figure(figsize=(15, 2.5 * num_datasets))  # Reduced height for less spacing\n",
    "    gs = gridspec.GridSpec(num_datasets, num_samples + 1, width_ratios=[0.2] + [1] * num_samples, hspace=0.3)  # Adjusted hspace for less vertical spacing\n",
    "    \n",
    "    # # Use Times New Roman font\n",
    "    # title_font = FontProperties(family='Times New Roman', weight='bold', size=18)  # Increased size\n",
    "    # dataset_font = FontProperties(family='Times New Roman', weight='bold', size=14)  # Increased size\n",
    "    # class_font = FontProperties(family='Times New Roman', size=12)  # Increased size\n",
    "\n",
    "    # Use a different font if Times New Roman is not available\n",
    "    title_font = FontProperties(family='DejaVu Sans', weight='bold', size=18)\n",
    "    dataset_font = FontProperties(family='DejaVu Sans', weight='bold', size=14)\n",
    "    class_font = FontProperties(family='DejaVu Sans', size=10)\n",
    "\n",
    "    # Set title\n",
    "    fig.suptitle(\"Comprehensive Visualization of Dataset Samples\", fontproperties=title_font, y=0.98)\n",
    "\n",
    "    for row_idx, (dataset_name, subset) in enumerate(datasets_to_show.items()):\n",
    "        # Add dataset name\n",
    "        ax = fig.add_subplot(gs[row_idx, 0])\n",
    "        ax.text(0.5, 0.5, dataset_name, fontproperties=dataset_font, \n",
    "                ha='center', va='center', rotation=0)\n",
    "        ax.axis('off')\n",
    "\n",
    "        class_names = class_names_dict.get(dataset_name, None)\n",
    "        \n",
    "        for col_idx in range(num_samples):\n",
    "            ax = fig.add_subplot(gs[row_idx, col_idx + 1])\n",
    "            try:\n",
    "                image, label = subset[col_idx]\n",
    "                image = im_convert(image)\n",
    "                ax.imshow(image)\n",
    "                \n",
    "                # Get class name\n",
    "                if class_names and label < len(class_names):\n",
    "                    class_name = class_names[label]\n",
    "                else:\n",
    "                    class_name = f\"Class {label}\"\n",
    "                \n",
    "                    # Start of Selection\n",
    "                    # Add class name as caption with adjusted position to ensure visibility without overlap\n",
    "                ax.text(0.5, -0.1, class_name, fontproperties=class_font,\n",
    "                    ha='center', va='bottom', transform=ax.transAxes,\n",
    "                    wrap=True, clip_on=False, color='black')\n",
    "\n",
    "                    # Add class name as caption\n",
    "                # ax.text(0.5, -0.1, class_name, fontproperties=class_font,\n",
    "                #         ha='center', va='top', transform=ax.transAxes,\n",
    "                #         wrap=True)\n",
    "            except IndexError:\n",
    "                ax.axis('off')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.92, bottom=0.05, left=0.05, right=0.95)  # Adjusted for better spacing\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute dataset visualization.\n",
    "    \"\"\"\n",
    "    root = \"../data/\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    num_samples = 5\n",
    "    datasets_to_show, class_names_dict = load_datasets(root, transform, num_samples=num_samples)\n",
    "\n",
    "    visualize_datasets(\n",
    "        datasets_to_show,\n",
    "        class_names_dict=class_names_dict,\n",
    "        num_samples=5,\n",
    "        save_path=\"publication_quality_dataset_samples.png\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', '/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf']\n",
      "Times New Roman is not available.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 列出所有可用字体\n",
    "available_fonts = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "print(available_fonts)\n",
    "\n",
    "# 检查 Times New Roman 是否在可用字体中\n",
    "if any('Times New Roman' in font for font in available_fonts):\n",
    "    print(\"Times New Roman is available.\")\n",
    "else:\n",
    "    print(\"Times New Roman is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sara",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
