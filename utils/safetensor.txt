lora_unet_input_blocks_1_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_1_0_emb_layers_1.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_1_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_1_0_emb_layers_1.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_1_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_1_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_1_0_in_layers_2.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_1_0_in_layers_2.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_1_0_in_layers_2.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_1_0_in_layers_2.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_1_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_1_0_out_layers_3.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_1_0_out_layers_3.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_1_0_out_layers_3.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_1_0_out_layers_3.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_2_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_2_0_emb_layers_1.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_2_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_2_0_emb_layers_1.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_2_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_2_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_2_0_in_layers_2.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_2_0_in_layers_2.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_2_0_in_layers_2.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_2_0_in_layers_2.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_2_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_2_0_out_layers_3.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_2_0_out_layers_3.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_2_0_out_layers_3.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_2_0_out_layers_3.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_3_0_op.alpha: torch.Size([])
lora_unet_input_blocks_3_0_op.lokr_w1_a: torch.Size([16, 4])
lora_unet_input_blocks_3_0_op.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_3_0_op.lokr_w2_a: torch.Size([20, 4])
lora_unet_input_blocks_3_0_op.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_4_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_4_0_emb_layers_1.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_4_0_emb_layers_1.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_4_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_4_0_in_layers_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_0_in_layers_2.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_4_0_in_layers_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_0_in_layers_2.lokr_w2_b: torch.Size([4, 180])
lora_unet_input_blocks_4_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_4_0_out_layers_3.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_0_out_layers_3.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_0_out_layers_3.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_0_out_layers_3.lokr_w2_b: torch.Size([4, 288])
lora_unet_input_blocks_4_0_skip_connection.alpha: torch.Size([])
lora_unet_input_blocks_4_0_skip_connection.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_0_skip_connection.lokr_w1_b: torch.Size([4, 16])
lora_unet_input_blocks_4_0_skip_connection.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_0_skip_connection.lokr_w2_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_proj_in.alpha: torch.Size([])
lora_unet_input_blocks_4_1_proj_in.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_proj_in.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_proj_in.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_proj_in.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_proj_out.alpha: torch.Size([])
lora_unet_input_blocks_4_1_proj_out.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_proj_out.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_proj_out.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_proj_out.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_input_blocks_5_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_5_0_emb_layers_1.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_5_0_emb_layers_1.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_5_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_5_0_in_layers_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_0_in_layers_2.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_0_in_layers_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_input_blocks_5_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_5_0_out_layers_3.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_0_out_layers_3.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_0_out_layers_3.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_0_out_layers_3.lokr_w2_b: torch.Size([4, 288])
lora_unet_input_blocks_5_1_proj_in.alpha: torch.Size([])
lora_unet_input_blocks_5_1_proj_in.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_proj_in.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_proj_in.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_proj_in.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_proj_out.alpha: torch.Size([])
lora_unet_input_blocks_5_1_proj_out.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_proj_out.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_proj_out.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_proj_out.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_input_blocks_6_0_op.alpha: torch.Size([])
lora_unet_input_blocks_6_0_op.lokr_w1_a: torch.Size([20, 4])
lora_unet_input_blocks_6_0_op.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_6_0_op.lokr_w2_a: torch.Size([32, 4])
lora_unet_input_blocks_6_0_op.lokr_w2_b: torch.Size([4, 288])
lora_unet_input_blocks_7_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_7_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_7_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_0_in_layers_2.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_7_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_input_blocks_7_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_7_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_input_blocks_7_0_skip_connection.alpha: torch.Size([])
lora_unet_input_blocks_7_0_skip_connection.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_0_skip_connection.lokr_w1_b: torch.Size([4, 20])
lora_unet_input_blocks_7_0_skip_connection.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_0_skip_connection.lokr_w2_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_proj_in.alpha: torch.Size([])
lora_unet_input_blocks_7_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_proj_out.alpha: torch.Size([])
lora_unet_input_blocks_7_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_7_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_0_emb_layers_1.alpha: torch.Size([])
lora_unet_input_blocks_8_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_0_in_layers_2.alpha: torch.Size([])
lora_unet_input_blocks_8_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_0_in_layers_2.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_0_in_layers_2.lokr_w2_b: torch.Size([4, 360])
lora_unet_input_blocks_8_0_out_layers_3.alpha: torch.Size([])
lora_unet_input_blocks_8_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_input_blocks_8_1_proj_in.alpha: torch.Size([])
lora_unet_input_blocks_8_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_proj_out.alpha: torch.Size([])
lora_unet_input_blocks_8_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_input_blocks_8_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_0_emb_layers_1.alpha: torch.Size([])
lora_unet_middle_block_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_0_in_layers_2.alpha: torch.Size([])
lora_unet_middle_block_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_0_in_layers_2.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_0_in_layers_2.lokr_w2_b: torch.Size([4, 360])
lora_unet_middle_block_0_out_layers_3.alpha: torch.Size([])
lora_unet_middle_block_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_middle_block_1_proj_in.alpha: torch.Size([])
lora_unet_middle_block_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_proj_out.alpha: torch.Size([])
lora_unet_middle_block_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_middle_block_2_emb_layers_1.alpha: torch.Size([])
lora_unet_middle_block_2_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_2_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_2_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_2_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_middle_block_2_in_layers_2.alpha: torch.Size([])
lora_unet_middle_block_2_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_2_in_layers_2.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_2_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_2_in_layers_2.lokr_w2_b: torch.Size([4, 360])
lora_unet_middle_block_2_out_layers_3.alpha: torch.Size([])
lora_unet_middle_block_2_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_middle_block_2_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_middle_block_2_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_middle_block_2_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_0_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_0_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_0_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_0_in_layers_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_0_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_0_in_layers_2.lokr_w2_b: torch.Size([4, 576])
lora_unet_output_blocks_0_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_0_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_0_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_0_0_skip_connection.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_0_skip_connection.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_0_0_skip_connection.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_0_skip_connection.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_0_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_0_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_0_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_1_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_1_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_0_in_layers_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_1_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_0_in_layers_2.lokr_w2_b: torch.Size([4, 576])
lora_unet_output_blocks_1_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_1_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_1_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_1_0_skip_connection.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_0_skip_connection.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_1_0_skip_connection.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_0_skip_connection.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_1_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_1_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_1_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_2_0_emb_layers_1.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_0_emb_layers_1.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_2_0_in_layers_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_0_in_layers_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_2_0_in_layers_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_0_in_layers_2.lokr_w2_b: torch.Size([4, 432])
lora_unet_output_blocks_2_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_2_0_out_layers_3.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_0_out_layers_3.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_0_out_layers_3.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_0_out_layers_3.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_2_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_2_0_skip_connection.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_0_skip_connection.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_2_0_skip_connection.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_0_skip_connection.lokr_w2_b: torch.Size([4, 48])
lora_unet_output_blocks_2_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_2_1_proj_in.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_proj_in.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_proj_in.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_proj_in.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_2_1_proj_out.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_proj_out.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_proj_out.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_proj_out.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_2_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_3_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_4_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_5_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_6_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_7_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_8_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_k.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_k.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_k.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_k.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_out_0.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_out_0.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_q.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_q.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_q.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_q.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_v.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_v.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_v.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_attn1_to_v.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_a: torch.Size([80, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_0_proj.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_a: torch.Size([128, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_0_proj.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_2.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_2.lokr_w1_b: torch.Size([4, 64])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_2.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_1_transformer_blocks_9_ff_net_2.lokr_w2_b: torch.Size([4, 80])
lora_unet_output_blocks_2_2_conv.alpha: torch.Size([])
lora_unet_output_blocks_2_2_conv.lokr_w1_a: torch.Size([32, 4])
lora_unet_output_blocks_2_2_conv.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_2_2_conv.lokr_w2_a: torch.Size([40, 4])
lora_unet_output_blocks_2_2_conv.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_3_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_3_0_emb_layers_1.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_3_0_emb_layers_1.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_3_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_3_0_in_layers_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_0_in_layers_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_3_0_in_layers_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_0_in_layers_2.lokr_w2_b: torch.Size([4, 432])
lora_unet_output_blocks_3_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_3_0_out_layers_3.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_0_out_layers_3.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_0_out_layers_3.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_0_out_layers_3.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_3_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_3_0_skip_connection.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_0_skip_connection.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_3_0_skip_connection.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_0_skip_connection.lokr_w2_b: torch.Size([4, 48])
lora_unet_output_blocks_3_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_3_1_proj_in.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_proj_in.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_proj_in.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_proj_in.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_3_1_proj_out.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_proj_out.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_proj_out.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_proj_out.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_3_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_4_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_4_0_emb_layers_1.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_4_0_emb_layers_1.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_4_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_4_0_in_layers_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_0_in_layers_2.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_4_0_in_layers_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_0_in_layers_2.lokr_w2_b: torch.Size([4, 360])
lora_unet_output_blocks_4_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_4_0_out_layers_3.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_0_out_layers_3.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_0_out_layers_3.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_0_out_layers_3.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_4_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_4_0_skip_connection.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_0_skip_connection.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_4_0_skip_connection.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_0_skip_connection.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_4_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_4_1_proj_in.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_proj_in.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_proj_in.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_proj_in.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_4_1_proj_out.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_proj_out.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_proj_out.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_proj_out.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_4_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_5_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_5_0_emb_layers_1.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_5_0_emb_layers_1.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_5_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_5_0_in_layers_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_0_in_layers_2.lokr_w1_b: torch.Size([4, 30])
lora_unet_output_blocks_5_0_in_layers_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_5_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_5_0_out_layers_3.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_0_out_layers_3.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_0_out_layers_3.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_0_out_layers_3.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_5_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_5_0_skip_connection.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_0_skip_connection.lokr_w1_b: torch.Size([4, 30])
lora_unet_output_blocks_5_0_skip_connection.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_0_skip_connection.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_proj_in.alpha: torch.Size([])
lora_unet_output_blocks_5_1_proj_in.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_proj_in.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_proj_in.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_proj_in.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_proj_out.alpha: torch.Size([])
lora_unet_output_blocks_5_1_proj_out.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_proj_out.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_proj_out.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_proj_out.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_0_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_k.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_k.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_out_0.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_q.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_q.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_v.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_attn1_to_v.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_a: torch.Size([64, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_a: torch.Size([80, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_0_proj.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_2.alpha: torch.Size([])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w1_b: torch.Size([4, 40])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_1_transformer_blocks_1_ff_net_2.lokr_w2_b: torch.Size([4, 64])
lora_unet_output_blocks_5_2_conv.alpha: torch.Size([])
lora_unet_output_blocks_5_2_conv.lokr_w1_a: torch.Size([20, 4])
lora_unet_output_blocks_5_2_conv.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_5_2_conv.lokr_w2_a: torch.Size([32, 4])
lora_unet_output_blocks_5_2_conv.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_6_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_6_0_emb_layers_1.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_6_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_6_0_emb_layers_1.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_6_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_6_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_6_0_in_layers_2.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_6_0_in_layers_2.lokr_w1_b: torch.Size([4, 30])
lora_unet_output_blocks_6_0_in_layers_2.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_6_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_6_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_6_0_out_layers_3.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_6_0_out_layers_3.lokr_w1_b: torch.Size([4, 16])
lora_unet_output_blocks_6_0_out_layers_3.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_6_0_out_layers_3.lokr_w2_b: torch.Size([4, 180])
lora_unet_output_blocks_6_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_6_0_skip_connection.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_6_0_skip_connection.lokr_w1_b: torch.Size([4, 30])
lora_unet_output_blocks_6_0_skip_connection.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_6_0_skip_connection.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_7_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_7_0_emb_layers_1.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_7_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_7_0_emb_layers_1.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_7_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_7_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_7_0_in_layers_2.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_7_0_in_layers_2.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_7_0_in_layers_2.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_7_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_7_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_7_0_out_layers_3.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_7_0_out_layers_3.lokr_w1_b: torch.Size([4, 16])
lora_unet_output_blocks_7_0_out_layers_3.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_7_0_out_layers_3.lokr_w2_b: torch.Size([4, 180])
lora_unet_output_blocks_7_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_7_0_skip_connection.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_7_0_skip_connection.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_7_0_skip_connection.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_7_0_skip_connection.lokr_w2_b: torch.Size([4, 32])
lora_unet_output_blocks_8_0_emb_layers_1.alpha: torch.Size([])
lora_unet_output_blocks_8_0_emb_layers_1.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_8_0_emb_layers_1.lokr_w1_b: torch.Size([4, 32])
lora_unet_output_blocks_8_0_emb_layers_1.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_8_0_emb_layers_1.lokr_w2_b: torch.Size([4, 40])
lora_unet_output_blocks_8_0_in_layers_2.alpha: torch.Size([])
lora_unet_output_blocks_8_0_in_layers_2.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_8_0_in_layers_2.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_8_0_in_layers_2.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_8_0_in_layers_2.lokr_w2_b: torch.Size([4, 288])
lora_unet_output_blocks_8_0_out_layers_3.alpha: torch.Size([])
lora_unet_output_blocks_8_0_out_layers_3.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_8_0_out_layers_3.lokr_w1_b: torch.Size([4, 16])
lora_unet_output_blocks_8_0_out_layers_3.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_8_0_out_layers_3.lokr_w2_b: torch.Size([4, 180])
lora_unet_output_blocks_8_0_skip_connection.alpha: torch.Size([])
lora_unet_output_blocks_8_0_skip_connection.lokr_w1_a: torch.Size([16, 4])
lora_unet_output_blocks_8_0_skip_connection.lokr_w1_b: torch.Size([4, 20])
lora_unet_output_blocks_8_0_skip_connection.lokr_w2_a: torch.Size([20, 4])
lora_unet_output_blocks_8_0_skip_connection.lokr_w2_b: torch.Size([4, 32])
